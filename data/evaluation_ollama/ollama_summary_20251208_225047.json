{
  "total_tests": 200,
  "model": "llama3.1:8b-instruct-q8_0",
  "overall": {
    "llm_keyword_avg": 0.5688333333333333,
    "rag_keyword_avg": 0.67325,
    "llm_time_avg": 2.9363,
    "rag_time_avg": 2.61015,
    "improvement": 0.1044166666666667
  },
  "comparison": {
    "rag_wins": 78,
    "llm_wins": 19,
    "ties": 103,
    "rag_win_rate": 39.0
  },
  "by_category": {
    "case_specific": {
      "llm_avg": 0.5688596491228071,
      "rag_avg": 0.6589912280701755,
      "improvement": 0.09013157894736844
    },
    "legal_principle": {
      "llm_avg": 0.5473684210526316,
      "rag_avg": 0.6589912280701755,
      "improvement": 0.11162280701754387
    },
    "procedure_detail": {
      "llm_avg": 0.6027777777777777,
      "rag_avg": 0.7184027777777778,
      "improvement": 0.11562500000000002
    }
  }
}